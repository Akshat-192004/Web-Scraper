{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import Session\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "\n",
    "with open(\"stage3.json\", \"r\") as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "logging.basicConfig(filename=\"new_logs.log\", format=\"%(asctime)s - %(message)s\", filemode=\"w\", level=logging.CRITICAL)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "session = Session()\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n",
    "}\n",
    "dir_name = \"optimized_documents\"\n",
    "\n",
    "\n",
    "def create_document_styles(document):\n",
    "    styles = document.styles\n",
    "    styles.add_style(\"MyHead\", WD_STYLE_TYPE.PARAGRAPH)\n",
    "\n",
    "    normal_styles = styles[\"Normal\"]\n",
    "    font = normal_styles.font\n",
    "    font.name = \"Tahoma\"\n",
    "    font.size = Pt(12)\n",
    "    normal_styles.paragraph_format.line_spacing = 1.15\n",
    "    normal_styles.paragraph_format.alignment = 3\n",
    "\n",
    "    heading_styles = styles[\"MyHead\"]\n",
    "    font = heading_styles.font\n",
    "    font.name = \"Tahoma\"\n",
    "    font.size = Pt(14)\n",
    "    font.color.rgb = None\n",
    "    font.bold = True\n",
    "\n",
    "def make_safe_filename(s):\n",
    "    def safe_char(c):\n",
    "        if c.isalnum():\n",
    "            return c\n",
    "        else:\n",
    "            return \"_\"\n",
    "    safe_string = \"\".join(safe_char(c) for c in s).rstrip(\"_\")\n",
    "    if(len(safe_string) > 150):\n",
    "        safe_string = safe_string[:150]\n",
    "    return safe_string\n",
    "\n",
    "def fetch_and_save_document(url, folder_path, url_index):\n",
    "    response = session.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    start_elem = soup.select_one(\"h2.make-database\")\n",
    "\n",
    "    if start_elem:\n",
    "        heading = (\n",
    "            start_elem.text.strip()\n",
    "            .replace(\"\\n\", \"\")\n",
    "            .replace(\"\\r\", \"\")\n",
    "            .replace(\"\\t\", \"\")\n",
    "        )\n",
    "        heading = (\n",
    "            heading.replace(\":\", \"-\").replace(\"?\", \"\").replace(\"*\", \"\").replace(\"<\", \"\")\n",
    "        )\n",
    "        heading = (\n",
    "            heading.replace(\">\", \"\")\n",
    "            .replace(\"|\", \"\")\n",
    "            .replace(\"/\", \"-\")\n",
    "            .replace(\"\\\\\", \"-\")\n",
    "            .replace('\"', \"\")\n",
    "        )\n",
    "\n",
    "        document = Document()\n",
    "        create_document_styles(document)\n",
    "\n",
    "        document.add_paragraph(heading).style = \"MyHead\"\n",
    "        all_elems = start_elem.find_all_next()\n",
    "\n",
    "        for elem in all_elems:\n",
    "            if elem.name == \"div\" and elem.get(\"class\") == [\"make-database\"]:\n",
    "                pdf_link = elem.find(\"a\").get(\"href\")\n",
    "                if pdf_link.startswith(\"..\") and pdf_link.endswith(\".pdf\"):\n",
    "                    temp = url if url.endswith(\"/\") else \"/\".join(url.split(\"/\")[:-1])\n",
    "                    pdf_link = urljoin(temp, pdf_link[2:])\n",
    "                else:\n",
    "                    pdf_link = urljoin(url, pdf_link)\n",
    "\n",
    "                res = session.get(pdf_link, stream=True, headers=headers)\n",
    "                file_name = make_safe_filename(heading)\n",
    "                pdf_file_path = os.path.join(folder_path, file_name + \".pdf\")\n",
    "                with open(pdf_file_path, \"wb\") as pdf:\n",
    "                    for chunk in res.iter_content(chunk_size=1024):\n",
    "                        if chunk:\n",
    "                            pdf.write(chunk)\n",
    "                logger.critical(f\"Fetched: {url_index}\")\n",
    "                return\n",
    "            elif elem.name == \"hr\" and elem.get(\"class\") == [\"make-database\"]:\n",
    "                break\n",
    "\n",
    "            data = (\n",
    "                elem.text.strip().replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \"\")\n",
    "            )\n",
    "            if data != \"\":\n",
    "                document.add_paragraph(data)\n",
    "        file_name = make_safe_filename(heading)\n",
    "        docx_file_path = os.path.join(folder_path, file_name + \".docx\")\n",
    "        document.save(docx_file_path)\n",
    "        logger.critical(f\"Fetched: {url_index}\")\n",
    "        \n",
    "        \n",
    "with ThreadPoolExecutor(max_workers=100) as executor:\n",
    "  for d in data:\n",
    "      title1 = d.get(\"title1\", \"\")\n",
    "      title1 = (\n",
    "          title1.replace(\":\", \"-\")\n",
    "          .replace(\"?\", \"\")\n",
    "          .replace(\"*\", \"\")\n",
    "          .replace(\"<\", \"\")\n",
    "          .replace(\">\", \"\")\n",
    "          .replace(\"|\", \"\")\n",
    "          .replace(\"/\", \"-\")\n",
    "          .replace(\"\\\\\", \"-\")\n",
    "          .replace('\"', \"\")\n",
    "      )\n",
    "      title2 = d.get(\"title2\", \"\")\n",
    "      title2 = (\n",
    "          title2.replace(\":\", \"-\")\n",
    "          .replace(\"?\", \"\")\n",
    "          .replace(\"*\", \"\")\n",
    "          .replace(\"<\", \"\")\n",
    "          .replace(\">\", \"\")\n",
    "          .replace(\"|\", \"\")\n",
    "          .replace(\"/\", \"-\")\n",
    "          .replace(\"\\\\\", \"-\")\n",
    "          .replace('\"', \"\")\n",
    "      )\n",
    "      title3 = d.get(\"title3\", \"\")\n",
    "      title3 = (\n",
    "          title3.replace(\":\", \"-\")\n",
    "          .replace(\"?\", \"\")\n",
    "          .replace(\"*\", \"\")\n",
    "          .replace(\"<\", \"\")\n",
    "          .replace(\">\", \"\")\n",
    "          .replace(\"|\", \"\")\n",
    "          .replace(\"/\", \"-\")\n",
    "          .replace(\"\\\\\", \"-\")\n",
    "          .replace('\"', \"\")\n",
    "      )\n",
    "      url = d.get(\"url\", \"\")\n",
    "      url_index = d.get(\"index\")\n",
    "      folder_path = os.path.join(dir_name, title1, title2)\n",
    "      if not os.path.exists(folder_path):\n",
    "          os.makedirs(folder_path)\n",
    "      executor.submit(fetch_and_save_document, url, folder_path, url_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
